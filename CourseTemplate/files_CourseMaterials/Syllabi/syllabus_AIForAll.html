<h1> Talk 1 (Jan 27, 2026): Generative AI and LLM on Your Laptop and on HPC Cluster: What is the Difference </h1>
<h2> Speaker:  Orion Lawlor </h2>
<p>
  <b>E-mail: </b> <a href='oslawlor@alaska.edu'>oslawlor@alaska.edu</a>
</p>

<p>
  <h3 >Abstract </h3>
  At our AI for All workshop this Tuesday from 10am-noon, we'll explore how you can run Large Language Models (LLMs) on your own local hardware using llamafile, ollama, and llama.cpp.  These models work best on a machine with a recent GPU or an Apple silicon Mac, but small models will run slowly on anything, and a local model gives much better privacy, predictability and technical control than is available with a cloud-hosted model.  This provides a clearer view of the underlying mechanics, limitations, and promise of this technology.  We will also demonstrate how we can run LLMs on the new GPUs on UAF's Chinook supercomputer, allowing us to use large models with the same local control.

  We will be installing several programs and discussing the internals of the models, and command line experience will be beneficial, but no programming is required.
</p>

<p>
  <h3> Materials shared by the speaker </h3>
  <b> Slide: </b>  <a href='https://docs.google.com/presentation/d/1nhmOEvF3YYlCGXwq8tMQo7QCm1rNgKqjNLy5gQo8yJI/edit?usp=sharing' target='_blank'>Link to Google slide</a>
  <br>
  <b> How to run an LLM model Locally: </b> <a href='https://docs.google.com/document/d/1opM_sGndXlB5OVG8H9REi15bbyrnfQsRaEbhN2J8aPY/edit?tab=t.0' target='_blank'> Link to Google Doc </a> (anyone can comment. Maintained by the speaker)
  <br>
  <b> A Chat Agent Hosted at UAF Chinook HPC: </b><a href='https://aurora.cs.uaf.edu/llm/gemma3/'> Link to a chat-agent </a> <br>(This instance is only for research, develoment, and testing. Do Not provide any confidential, or proprietery, or personal information)
</p>
<hr>
<h1> Talk 2 (Feb 10, 2026): Linux Foundation: Beginnerâ€™s intro to command line </h1>
<h2> Speaker: Kevin Galloway </h2>
<p>
  <b>E-mail: </b> <a href='kpgalloway@alaska.edu'>kpgalloway@alaska.edu</a>
</p>
<p>
  <h3 >Abstract </h3>
  In this AI for All workshop, Tuesday, Feb.10, 10am-12pm, we'll cover the basics of the Linux command line in order to prepare yourself for using LLMs locally or High Performance Computing resources remotely to train these models, or run other data analyses. We'll cover the basics of what Linux is and why we use the command line. We'll demonstrate commands to traverse the filesystem, get information from the system, and many file operation commands such as reading and editing files, along with copying and moving them. In addition we will also cover a brief introduction to Bash scripting to introduce you to run commands multiple times.
  <br>
We will be creating files and directories and running some shell scripts. For participation, access to a Linux computer, Windows Subsystem for Linux, or a MacOS system is encouraged, no programming is required.

</p>

<p>
  <h3> Materials shared by the speaker </h3>
  <b>Slides: </b> <a href='https://docs.google.com/presentation/d/1Wkm_ceMxF56U2f_5NrXtihQcnLh7fv-Ly5pd5EwOsGw/edit?usp=sharing' target='_blank'> Link to Google Slide </a>
  <br>
  <b>Get a Linux terminal on UAF Chinook HPC: </b> <a href='https://www.gi.alaska.edu/form/user-account-application-rcs-' target='_blank'>Fill out this form</a> (This option is for UA affiliated persons)
  <br>
  <b>For non-UA persons:</b> <a href='https://uaf-rcs.gitbook.io/uaf-rcs-hpc-docs/request-an-account' target='_blank'>Follow these steps</a>
</p>

